{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1db647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48a9767",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa25a65c",
   "metadata": {},
   "source": [
    "# BASNET ATTEMPT 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91c61565",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(tf.keras.Model):\n",
    "    def __init__(self,channel,stride=1):\n",
    "        super(ResBlock,self).__init__(name='res_block')\n",
    "        self.flag = (stride != 1)\n",
    "        self.cn1 = layers.Conv2D(channel,3,stride,padding='same')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.cn2 = layers.Conv2D(channel,3,padding='same')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        if self.flag:\n",
    "            self.bn3 = layers.BatchNormalization()\n",
    "            self.cn3 = layers.Conv2D(channel,1,stride)\n",
    "            \n",
    "    def call(self,x):\n",
    "        x1 = self.cn1(x)\n",
    "        x1 = self.bn1(x1)\n",
    "        x1 = self.relu(x1)\n",
    "        x1 = self.cn2(x1)\n",
    "        x1 = self.bn2(x1)\n",
    "        if self.flag:\n",
    "            x1 = self.cn3(x1)\n",
    "            x1 = self.bn3(x1)\n",
    "        x1 = layers.add([x,x1])\n",
    "        x1 = self.relu(x1)\n",
    "        return x1\n",
    "            \n",
    "        \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cb214ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefUnet(tf.keras.Model):\n",
    "    def __init__(self,channel):\n",
    "        super(RefUnet,self).__init__()\n",
    "        \n",
    "        self.conv0 = layers.Conv2D(channel,3,padding='same')\n",
    "\n",
    "        self.conv1 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu1 = layers.ReLU()\n",
    "\n",
    "        self.pool1 = layers.MaxPool2D(2,2)\n",
    "\n",
    "        self.conv2 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn2 = layers.BatchNormalization(64)\n",
    "        self.relu2 = layers.ReLU()\n",
    "\n",
    "        self.pool2 = layers.MaxPool2D(2,2)\n",
    "\n",
    "        self.conv3 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn3 = layers.BatchNormalization(64)\n",
    "        self.relu3 = layers.ReLU()\n",
    "\n",
    "        self.pool3 = layers.MaxPool2D(2,2)\n",
    "\n",
    "        self.conv4 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn4 = layers.BatchNormalization(64)\n",
    "        self.relu4 = layers.ReLU()\n",
    "\n",
    "        self.pool4 = layers.MaxPool2D(2,2)\n",
    "\n",
    "        #####\n",
    "\n",
    "        self.conv5 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn5 = layers.BatchNormalization(64)\n",
    "        self.relu5 = layers.ReLU()\n",
    "\n",
    "        #####\n",
    "\n",
    "        self.conv_d4 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn_d4 = layers.BatchNormalization(64)\n",
    "        self.relu_d4 = layers.ReLU()\n",
    "\n",
    "        self.conv_d3 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn_d3 = layers.BatchNormalization(64)\n",
    "        self.relu_d3 = layers.ReLU()\n",
    "\n",
    "        self.conv_d2 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn_d2 = layers.BatchNormalization(64)\n",
    "        self.relu_d2 = layers.ReLU()\n",
    "\n",
    "        self.conv_d1 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn_d1 = layers.BatchNormalization(64)\n",
    "        self.relu_d1 = layers.ReLU()\n",
    "\n",
    "        self.conv_d0 = layers.Conv2D(1,3,padding='same')\n",
    "\n",
    "        self.upscore2 = layers.UpSampling2D(2,interpolation='bilinear')\n",
    "        \n",
    "        def call(self,x):\n",
    "            hx = x\n",
    "            hx = self.conv0(hx)\n",
    "\n",
    "            hx1 = self.relu1(self.bn1(self.conv1(hx)))\n",
    "            hx = self.pool1(hx1)\n",
    "\n",
    "            hx2 = self.relu2(self.bn2(self.conv2(hx)))\n",
    "            hx = self.pool2(hx2)\n",
    "\n",
    "            hx3 = self.relu3(self.bn3(self.conv3(hx)))\n",
    "            hx = self.pool3(hx3)\n",
    "\n",
    "            hx4 = self.relu4(self.bn4(self.conv4(hx)))\n",
    "            hx = self.pool4(hx4)\n",
    "\n",
    "            hx5 = self.relu5(self.bn5(self.conv5(hx)))\n",
    "\n",
    "            hx = self.upscore2(hx5)\n",
    "\n",
    "            d4 = self.relu_d4(self.bn_d4(self.conv_d4(torch.cat((hx,hx4),1))))\n",
    "            hx = self.upscore2(d4)\n",
    "\n",
    "            d3 = self.relu_d3(self.bn_d3(self.conv_d3(torch.cat((hx,hx3),1))))\n",
    "            hx = self.upscore2(d3)\n",
    "\n",
    "            d2 = self.relu_d2(self.bn_d2(self.conv_d2(torch.cat((hx,hx2),1))))\n",
    "            hx = self.upscore2(d2)\n",
    "\n",
    "            d1 = self.relu_d1(self.bn_d1(self.conv_d1(torch.cat((hx,hx1),1))))\n",
    "\n",
    "            residual = self.conv_d0(d1)\n",
    "\n",
    "            return x + residual\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92effbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(BasNet,self).__init__(name='res_net_encoder')\n",
    "        \n",
    "        '''\n",
    "        Input layer \n",
    "        '''\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(64,3,1,padding='same')\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        '''\n",
    "        ResNetwork Encoder\n",
    "        '''\n",
    "        \n",
    "        # stage 1\n",
    "        self.conv2_1 = ResBlock(64)\n",
    "        self.conv2_2 = ResBlock(64)\n",
    "        self.conv2_3 = ResBlock(64)\n",
    "\n",
    "        # stage 2\n",
    "        self.conv3_1 = ResBlock(128, 2)\n",
    "        self.conv3_2 = ResBlock(128)\n",
    "        self.conv3_3 = ResBlock(128)\n",
    "        self.conv3_4 = ResBlock(128)\n",
    "\n",
    "        # stage 3\n",
    "        self.conv4_1 = ResBlock(256, 2)\n",
    "        self.conv4_2 = ResBlock(256)\n",
    "        self.conv4_3 = ResBlock(256)\n",
    "        self.conv4_4 = ResBlock(256)\n",
    "        self.conv4_5 = ResBlock(256)\n",
    "        self.conv4_6 = ResBlock(256)\n",
    "        \n",
    "        # stage 4\n",
    "        self.conv5_1 = ResBlock(512, 2)\n",
    "        self.conv5_2 = ResBlock(512)\n",
    "        self.conv5_3 = ResBlock(512)\n",
    "        \n",
    "        self.max_pool = layers.MaxPool2D(2,2)\n",
    "        \n",
    "        # stage 5\n",
    "        self.resb6_1 = ResBlock(512)\n",
    "        self.resb6_2 = ResBlock(512)\n",
    "        self.resb6_3 = ResBlock(512)\n",
    "        \n",
    "        self.max_pool2 = layers.MaxPool2D(2,2)\n",
    "        \n",
    "        # stage 6\n",
    "        self.resb7_1 = ResBlock(512)\n",
    "        self.resb7_2 = ResBlock(512)\n",
    "        self.resb7_3 = ResBlock(512)\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        Bridge\n",
    "        '''\n",
    "        self.convbg_1 = layers.Conv2D(512,3,dilation_rate=2 , padding='same')\n",
    "        self.bnbg_1 = layers.BatchNormalization()\n",
    "        self.relubg_1 = layers.ReLU()\n",
    "        self.convbg_m = layers.Conv2D(512,3,dilation_rate=2 , padding='same')\n",
    "        self.bnbg_m = layers.BatchNormalization()\n",
    "        self.relubg_m = layers.ReLU()\n",
    "        self.convbg_2 = layers.Conv2D(512,3,dilation_rate=2 , padding='same')\n",
    "        self.bnbg_2 = layers.BatchNormalization()\n",
    "        self.relubg_2 = layers.ReLU()\n",
    "        \n",
    "        '''\n",
    "        Decoder\n",
    "        '''\n",
    "        #stage 6 \n",
    "        self.conv6d_1 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bn6d_1 = layers.BatchNormalization()\n",
    "        self.relu6d_1 = layers.ReLU()\n",
    "        \n",
    "        self.conv6d_2 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bn6d_2 = layers.BatchNormalization()\n",
    "        self.relu6d_2 = layers.ReLU()\n",
    "        \n",
    "        self.conv6d_3 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bn6d_3 = layers.BatchNormalization()\n",
    "        self.relu6d_3 = layers.ReLU()\n",
    "        \n",
    "        #stage 5\n",
    "        self.conv5d_1 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bn5d_1 = layers.BatchNormalization()\n",
    "        self.relu5d_1 = layers.ReLU()\n",
    "        \n",
    "        self.conv5d_2 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bn5d_2 = layers.BatchNormalization()\n",
    "        self.relu5d_2 = layers.ReLU()\n",
    "        \n",
    "        self.conv5d_3 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bn5d_3 = layers.BatchNormalization()\n",
    "        self.relu5d_3 = layers.ReLU()\n",
    "        \n",
    "        #stage 4 \n",
    "        self.conv4d_1 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bn4d_1 = layers.BatchNormalization()\n",
    "        self.relu4d_1 = layers.ReLU()\n",
    "        \n",
    "        self.conv4d_2 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bn4d_2 = layers.BatchNormalization()\n",
    "        self.relu4d_2 = layers.ReLU()\n",
    "        \n",
    "        self.conv4d_3 = layers.Conv2D(256,3,padding='same')\n",
    "        self.bn4d_3 = layers.BatchNormalization()\n",
    "        self.relu4d_3 = layers.ReLU()\n",
    "        \n",
    "        #stage 3\n",
    "        self.conv3d_1 = layers.Conv2D(256,3,padding='same')\n",
    "        self.bn3d_1 = layers.BatchNormalization()\n",
    "        self.relu3d_1 = layers.ReLU()\n",
    "        \n",
    "        self.conv3d_2 = layers.Conv2D(256,3,padding='same')\n",
    "        self.bn3d_2 = layers.BatchNormalization()\n",
    "        self.relu3d_2 = layers.ReLU()\n",
    "        \n",
    "        self.conv3d_3 = layers.Conv2D(128,3,padding='same')\n",
    "        self.bn3d_3 = layers.BatchNormalization()\n",
    "        self.relu3d_3 = layers.ReLU()\n",
    "        \n",
    "        #stage 2\n",
    "        self.conv2d_1 = layers.Conv2D(128,3,padding='same')\n",
    "        self.bn2d_1 = layers.BatchNormalization()\n",
    "        self.relu2d_1 = layers.ReLU()\n",
    "        \n",
    "        self.conv2d_2 = layers.Conv2D(128,3,padding='same')\n",
    "        self.bn2d_2 = layers.BatchNormalization()\n",
    "        self.relu2d_2 = layers.ReLU()\n",
    "        \n",
    "        self.conv2d_3 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn2d_3 = layers.BatchNormalization()\n",
    "        self.relu2d_3 = layers.ReLU()\n",
    "        \n",
    "        #stage1\n",
    "        self.conv1d_1 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn1d_1 = layers.BatchNormalization()\n",
    "        self.relu1d_1 = layers.ReLU()\n",
    "        \n",
    "        self.conv1d_2 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn1d_2 = layers.BatchNormalization()\n",
    "        self.relu1d_2 = layers.ReLU()\n",
    "        \n",
    "        self.conv1d_3 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn1d_3 = layers.BatchNormalization()\n",
    "        self.relu1d_3 = layers.ReLU()\n",
    "        \n",
    "          ## -------------Bilinear Upsampling--------------\n",
    "            \n",
    "        self.upscore6 = layers.UpSampling2D(32,interpolation='bilinear')\n",
    "        self.upscore5 = layers.UpSampling2D(16,interpolation='bilinear')\n",
    "        self.upscore4 = layers.UpSampling2D(8,interpolation='bilinear')\n",
    "        self.upscore3 = layers.UpSampling2D(4,interpolation='bilinear')\n",
    "        self.upscore2 = layers.UpSampling2D(2,interpolation='bilinear')\n",
    "        \n",
    "        ## -------------Side Output--------------\n",
    "        self.outconvb = layers.Conv2D(1,3,padding='same')\n",
    "        self.outconv6 = layers.Conv2D(1,3,padding='same')\n",
    "        self.outconv5 = layers.Conv2D(1,3,padding='same')\n",
    "        self.outconv4 = layers.Conv2D(1,3,padding='same')\n",
    "        self.outconv3 = layers.Conv2D(1,3,padding='same')\n",
    "        self.outconv2 = layers.Conv2D(1,3,padding='same')\n",
    "        self.outconv1 = layers.Conv2D(1,3,padding='same')\n",
    "        \n",
    "        ## Refine module \n",
    "        self.refNet = RefUnet(64)\n",
    "        \n",
    "    \n",
    "    def call(self, x):\n",
    "        hx = x\n",
    "        #--------------Encoder-------------\n",
    "        hx = self.conv1(hx)\n",
    "        hx = self.bn(hx)\n",
    "        hx = self.relu(hx)\n",
    "        # stage1\n",
    "        h1 = self.conv2_1(hx)\n",
    "        h1 = self.conv2_2(h1)\n",
    "        h1 = self.conv2_3(h1)\n",
    "        #stage2 \n",
    "        h2 = self.conv3_1(h1)\n",
    "        h2 = self.conv3_2(h2)\n",
    "        h2 = self.conv3_3(h2)\n",
    "        h2 = self.conv3_4(h2)\n",
    "        #stage 3\n",
    "        h3 = self.conv4_1(h2)\n",
    "        h3 = self.conv4_2(h3)\n",
    "        h3 = self.conv4_3(h3)\n",
    "        h3 = self.conv4_4(h3)\n",
    "        h3 = self.conv4_5(h3)\n",
    "        h3 = self.conv4_6(h3)\n",
    "        #stage 4 \n",
    "        h4 = self.conv5_1(h3)\n",
    "        h4 = self.conv5_2(h4)\n",
    "        h4 = self.conv5_3(h4)\n",
    "        \n",
    "        hx = self.max_pool(h4)\n",
    "        \n",
    "        hx = resb6_1(hx)\n",
    "        hx = resb6_2(hx)\n",
    "        h5 = resb6_3(hx)\n",
    "        \n",
    "        hx = self.max_pool(h5)\n",
    "        \n",
    "        hx = resb7_1(hx)\n",
    "        hx = resb7_2(hx)\n",
    "        h6 = resb7_3(hx)\n",
    "        \n",
    "        #------------Bridge--------------\n",
    "        \n",
    "        hx = self.relubg_1(self.bnbg_1(self.convbg_1(h6))) \n",
    "        hx = self.relubg_m(self.bnbg_m(self.convbg_m(hx)))\n",
    "        hbg = self.relubg_2(self.bnbg_2(self.convbg_2(hx)))\n",
    "        \n",
    "        ## -------------Decoder-------------\n",
    "        hx = self.relu6d_1(self.bn6d_1(self.conv6d_1(tf.concat((hbg,h6),1))))\n",
    "        hx = self.relu6d_m(self.bn6d_m(self.conv6d_m(hx)))\n",
    "        hd6 = self.relu6d_2(self.bn6d_2(self.conv6d_2(hx)))\n",
    "\n",
    "        hx = self.upscore2(hd6) # 8 -> 16\n",
    "\n",
    "        hx = self.relu5d_1(self.bn5d_1(self.conv5d_1(tf.concat((hx,h5),1))))\n",
    "        hx = self.relu5d_m(self.bn5d_m(self.conv5d_m(hx)))\n",
    "        hd5 = self.relu5d_2(self.bn5d_2(self.conv5d_2(hx)))\n",
    "\n",
    "        hx = self.upscore2(hd5) # 16 -> 32\n",
    "\n",
    "        hx = self.relu4d_1(self.bn4d_1(self.conv4d_1(tf.concat((hx,h4),1))))\n",
    "        hx = self.relu4d_m(self.bn4d_m(self.conv4d_m(hx)))\n",
    "        hd4 = self.relu4d_2(self.bn4d_2(self.conv4d_2(hx)))\n",
    "\n",
    "        hx = self.upscore2(hd4) # 32 -> 64\n",
    "\n",
    "        hx = self.relu3d_1(self.bn3d_1(self.conv3d_1(tf.concat((hx,h3),1))))\n",
    "        hx = self.relu3d_m(self.bn3d_m(self.conv3d_m(hx)))\n",
    "        hd3 = self.relu3d_2(self.bn3d_2(self.conv3d_2(hx)))\n",
    "\n",
    "        hx = self.upscore2(hd3) # 64 -> 128\n",
    "\n",
    "        hx = self.relu2d_1(self.bn2d_1(self.conv2d_1(tf.concat((hx,h2),1))))\n",
    "        hx = self.relu2d_m(self.bn2d_m(self.conv2d_m(hx)))\n",
    "        hd2 = self.relu2d_2(self.bn2d_2(self.conv2d_2(hx)))\n",
    "\n",
    "        hx = self.upscore2(hd2) # 128 -> 256\n",
    "\n",
    "        hx = self.relu1d_1(self.bn1d_1(self.conv1d_1(tf.concat((hx,h1),1))))\n",
    "        hx = self.relu1d_m(self.bn1d_m(self.conv1d_m(hx)))\n",
    "        hd1 = self.relu1d_2(self.bn1d_2(self.conv1d_2(hx)))\n",
    "        \n",
    "        db = self.outconvb(hbg)\n",
    "        db = self.upscore6(db) # 8->256\n",
    "\n",
    "        d6 = self.outconv6(hd6)\n",
    "        d6 = self.upscore6(d6) # 8->256\n",
    "\n",
    "        d5 = self.outconv5(hd5)\n",
    "        d5 = self.upscore5(d5) # 16->256\n",
    "\n",
    "        d4 = self.outconv4(hd4)\n",
    "        d4 = self.upscore4(d4) # 32->256\n",
    "\n",
    "        d3 = self.outconv3(hd3)\n",
    "        d3 = self.upscore3(d3) # 64->256\n",
    "\n",
    "        d2 = self.outconv2(hd2)\n",
    "        d2 = self.upscore2(d2) # 128->256\n",
    "\n",
    "        d1 = self.outconv1(hd1) # 256\n",
    "\n",
    "        ## -------------Refine Module-------------\n",
    "        dout = self.refNet(d1) # 256\n",
    "        \n",
    "        return tf.keras.activations.sigmoid(dout), tf.keras.activations.sigmoid(d1), tf.keras.activations.sigmoid(d2), tf.keras.activations.sigmoid(d3), tf.keras.activations.sigmoid(d4), tf.keras.activations.sigmoid(d5), tf.keras.activations.sigmoid(d6), tf.keras.activations.sigmoid(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5030cd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "748ae1ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"res_block\" (type ResBlock).\n\nin user code:\n\n    File \"C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_10224\\3447930896.py\", line 23, in call  *\n        x1 = layers.add([x,x1])\n    File \"E:\\MACHINELEARNING\\TENSORFLOW_P\\tensorflow\\lib\\site-packages\\keras\\layers\\merge.py\", line 791, in add  **\n        return Add(**kwargs)(inputs)\n    File \"E:\\MACHINELEARNING\\TENSORFLOW_P\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"E:\\MACHINELEARNING\\TENSORFLOW_P\\tensorflow\\lib\\site-packages\\keras\\layers\\merge.py\", line 78, in _compute_elemwise_op_output_shape\n        raise ValueError(\n\n    ValueError: Inputs have incompatible shapes. Received shapes (224, 224, 64) and (56, 56, 128)\n\n\nCall arguments received:\n  • x=tf.Tensor(shape=(1, 224, 224, 64), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\MACHINELEARNING\\TENSORFLOW_P\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:440\u001b[0m, in \u001b[0;36mModel.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    436\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    437\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou can only call `build()` on a model if its `call()` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    438\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod accepts an `inputs` argument.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 440\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mInvalidArgumentError, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    442\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou cannot build your model by calling `build` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    443\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mif your layers do not support float type inputs. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    444\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInstead, in order to instantiate and build your \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    445\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel, call your model on real tensor data (of \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    446\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe correct dtype).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThe actual error from \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    447\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`call` is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36mBasNet.call\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    179\u001b[0m h1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2_3(h1)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m#stage2 \u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m h2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m h2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3_2(h2)\n\u001b[0;32m    183\u001b[0m h2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3_3(h2)\n",
      "File \u001b[1;32mE:\\MACHINELEARNING\\TENSORFLOW_P\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mE:\\MACHINELEARNING\\TENSORFLOW_P\\tensorflow\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    693\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"res_block\" (type ResBlock).\n\nin user code:\n\n    File \"C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_10224\\3447930896.py\", line 23, in call  *\n        x1 = layers.add([x,x1])\n    File \"E:\\MACHINELEARNING\\TENSORFLOW_P\\tensorflow\\lib\\site-packages\\keras\\layers\\merge.py\", line 791, in add  **\n        return Add(**kwargs)(inputs)\n    File \"E:\\MACHINELEARNING\\TENSORFLOW_P\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"E:\\MACHINELEARNING\\TENSORFLOW_P\\tensorflow\\lib\\site-packages\\keras\\layers\\merge.py\", line 78, in _compute_elemwise_op_output_shape\n        raise ValueError(\n\n    ValueError: Inputs have incompatible shapes. Received shapes (224, 224, 64) and (56, 56, 128)\n\n\nCall arguments received:\n  • x=tf.Tensor(shape=(1, 224, 224, 64), dtype=float32)"
     ]
    }
   ],
   "source": [
    "model.build([1,224,224,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5d1f868",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ResBlock(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a40a60e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.build([1,224,224,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aace4d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"res_block\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_521 (Conv2D)         multiple                  84        \n",
      "                                                                 \n",
      " batch_normalization_493 (Ba  multiple                 12        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_522 (Conv2D)         multiple                  84        \n",
      "                                                                 \n",
      " batch_normalization_494 (Ba  multiple                 12        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_318 (ReLU)            multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 192\n",
      "Trainable params: 180\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41e25ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10(tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
