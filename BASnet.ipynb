{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1db647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af382105",
   "metadata": {},
   "source": [
    "# BASNET ATTEMPT 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079857d7",
   "metadata": {},
   "source": [
    "**Basic Architecture of BASNet consist of two Module, Prediction Module and Refined Module**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f03033d",
   "metadata": {},
   "source": [
    "- lets start with prediction Module\n",
    "- Construct helper function \n",
    "- The Prediction module is U-Net like structure (encoder-decoder)\n",
    "- For Encoder we are going to use residual blocks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab448e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class basicBlock(tf.keras.Model):\n",
    "    def __init__(self,filters,stride=1):\n",
    "        super(basicBlock,self).__init__()\n",
    "        self.conv1 = layers.Conv2D(filters,3,strides = stride,padding='same')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu1 = layers.Activation('relu')\n",
    "        self.conv2 = layers.Conv2D(filters,3,strides=1,padding='same')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.relu2 = layers.Activation('relu')\n",
    "        \n",
    "    def call(self,x_in):\n",
    "        res = x_in\n",
    "        x = self.conv1(res)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = layers.add([x,res])\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "779c772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class reslayer1(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(reslayer1,self).__init__()\n",
    "        self.convblock1 = basicBlock(64)\n",
    "        self.convblock2 = basicBlock(64)\n",
    "        self.convblock3 = basicBlock(64)\n",
    "        \n",
    "    def call(self,x_in):\n",
    "        x = self.convblock1(x_in)\n",
    "        x =  slef.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f104d1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class reslayer2(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(reslayer2,self).__init__()\n",
    "        self.convblock1 = basicBlock(128,2)\n",
    "        self.convblock2 = basicBlock(128)\n",
    "        self.convblock3 = basicBlock(128)\n",
    "        self.convblock4 = basicBlock(128)\n",
    "        \n",
    "    def call(self,x_in):\n",
    "        x = self.convblock1(x_in)\n",
    "        x =  slef.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        x = self.convblock4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbe06951",
   "metadata": {},
   "outputs": [],
   "source": [
    "class reslayer3(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(reslayer3,self).__init__()\n",
    "        self.convblock1 = basicBlock(256,2)\n",
    "        self.convblock2 = basicBlock(256)\n",
    "        self.convblock3 = basicBlock(256)\n",
    "        self.convblock4 = basicBlock(256)\n",
    "        self.convblock5 = basicBlock(256)\n",
    "        self.convblock6 = basicBlock(256)\n",
    "        \n",
    "    def call(self,x_in):\n",
    "        x = self.convblock1(x_in)\n",
    "        x =  slef.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        x = self.convblock4(x)\n",
    "        x = self.convblock5(x)\n",
    "        x = self.convblock6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5f26eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class reslayer4(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(reslayer4,self).__init__()\n",
    "        self.convblock1 = basicBlock(512,2)\n",
    "        self.convblock2 = basicBlock(512)\n",
    "        self.convblock3 = basicBlock(512)\n",
    "        \n",
    "    def call(self,x_in):\n",
    "        x = self.convblock1(x_in)\n",
    "        x =  slef.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b153ddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefUnet(tf.keras.Model):\n",
    "    def __init__(self,filters):\n",
    "        super(RefUnet,self).__init__()\n",
    "        self.conv0 = layers.Conv2D(filters,3,padding='same')\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu1 = layers.Activation('relu')\n",
    "        \n",
    "        self.pool1=layers.MaxPool2D()\n",
    "        \n",
    "        self.conv2 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.relu2 = layers.Activation('relu')\n",
    "        \n",
    "        self.pool2=layers.MaxPool2D()\n",
    "        \n",
    "        self.conv3 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        self.relu3 = layers.Activation('relu')\n",
    "        \n",
    "        self.pool3=layers.MaxPool2D()\n",
    "        \n",
    "        self.conv4 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        self.relu4 = layers.Activation('relu')\n",
    "        \n",
    "        self.pool4=layers.MaxPool2D()\n",
    "        ######\n",
    "        self.conv5 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn5 = layers.BatchNormalization()\n",
    "        self.relu5 = layers.Activation('relu')\n",
    "        \n",
    "        ####\n",
    "        \n",
    "        self.convd_4 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd_4 = layers.BatchNormalization()\n",
    "        self.relud_4 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd_3 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd_3 = layers.BatchNormalization()\n",
    "        self.relud_3 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd_2 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd_2 = layers.BatchNormalization()\n",
    "        self.relud_2 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd_1 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd_1 = layers.BatchNormalization()\n",
    "        self.relud_1  = layers.Activation('relu')\n",
    "        \n",
    "        self.convd_0 = layers.Conv2D(1,3,padding='same')\n",
    "        self.upscore2 = layers.UpSampling2D(2,interpolation='bilinear')\n",
    "        \n",
    "    def call(self,x):\n",
    "        hx = x\n",
    "        hx = self.conv0(hx)\n",
    "        \n",
    "        hx1 = self.relu1(self.bn1(self.conv1(hx)))\n",
    "        hx = self.pool1(hx1)\n",
    "        \n",
    "        hx2 = self.relu2(self.bn2(self.conv2(hx)))\n",
    "        hx = self.pool2(hx2)\n",
    "        \n",
    "        hx3 = self.relu3(self.bn3(self.conv3(hx)))\n",
    "        hx = self.pool3(hx3)\n",
    "        \n",
    "        hx4 = self.relu4(self.bn4(self.conv4(hx)))\n",
    "        hx = self.pool4(hx4)\n",
    "        \n",
    "        hx5 = self.relu5(self.bn5(self.conv5(hx)))\n",
    "        \n",
    "        \n",
    "        hx = self.upscore2(hx5)\n",
    "        \n",
    "        d4 = self.relud_4(self.bnd_4(self.convd_4(layers.Concatenate(1)([hx,hx4]))))\n",
    "        hx = self.upscore2(d4)\n",
    "        \n",
    "        d3 = self.relud_3(self.bnd_3(self.convd_3(layers.Concatenate(1)([hx,hx3]))))\n",
    "        hx = self.upscore2(d3)\n",
    "        \n",
    "        d2 = self.relud_2(self.bnd_2(self.convd_2(layers.Concatenate(1)([hx,hx2]))))\n",
    "        hx = self.upscore2(d2)\n",
    "        \n",
    "        d1 = self.relud_1(self.bnd_1(self.convd_1(layers.Concatenate(1)([hx,hx1]))))\n",
    "        \n",
    "        residual = self.convd_0(d1)\n",
    "        \n",
    "        return x + residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320021b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasNet(tf.keras.Model):\n",
    "    def __inti__(self):\n",
    "        super(BasNet,self).__init__()\n",
    "        #------------Encoeder------------------\n",
    "        self.in = layers.Input(shape=(224,224,3))\n",
    "        self.inconv = layers.Conv2D(64,3,stride = 1,padding='same')\n",
    "        self.inbn = layers.BatchNormalization()\n",
    "        self.inrelu = layers.Activation('relu')\n",
    "        \n",
    "        #stage 1 \n",
    "        self.encoder1 = reslayer1()#64\n",
    "        #stage 2 \n",
    "        self.encoder2 = reslayer2()#128\n",
    "        #stage 3\n",
    "        self.encoder3 = reslayer3()#256\n",
    "        #stage 4\n",
    "        self.encoder4 = reslayer4()#512\n",
    "        \n",
    "        self.pool4 = layers.MaxPool2D()\n",
    "        \n",
    "        #stage 5\n",
    "        self.resb5_1 = basicBlock(512)\n",
    "        self.resb5_2 = basicBlock(512)\n",
    "        self.resb5_3 = basicBlock(512)\n",
    "        \n",
    "        self.pool5 = layers.MaxPool2D()\n",
    "        \n",
    "        #stage 6\n",
    "        self.resb6_1 = basicBlock(512)\n",
    "        self.resb6_2 = basicBlock(512)\n",
    "        self.resb6_3 = basicBlock(512)\n",
    "        \n",
    "        \n",
    "        #----------------Bridge------------------------\n",
    "        #stage bridge\n",
    "        self.convbg_1 = layers.Conv2D(512,3,dilation_rate=2)\n",
    "        self.bnbg_1 = layers.BatchNormalization()\n",
    "        self.relubg_1 = layers.Activation('relu')\n",
    "        self.convbg_2 = layers.Conv2D(512,3,dilation_rate=2)\n",
    "        self.bnbg_2 = layers.BatchNormalization()\n",
    "        self.relubg_2 = layers.Activation('relu')\n",
    "        self.convbg_3 = layers.Conv2D(512,3,dilation_rate=2)\n",
    "        self.bnbg_3 = layers.BatchNormalization()\n",
    "        self.relubg_3 = layers.Activation('relu')\n",
    "        \n",
    "        #-------------------Decoder----------------------\n",
    "        \n",
    "        #stage 6d\n",
    "        self.convd6_1 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bnd6_1 = layers.BatchNormalization()\n",
    "        self.relud6_1 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd6_2 = layers.Conv2D(512,3,dilation_rate=2,padding='same')\n",
    "        self.bnd6_2 = layers.BatchNormalization()\n",
    "        self.relud6_2 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd6_3 = layers.Conv2D(512,3,dilation_rate=2,padding='same')\n",
    "        self.bnd6_3 = layers.BatchNormalization()\n",
    "        self.relud6_3 = layers.Activation('relu')\n",
    "        \n",
    "        #stage 5d\n",
    "        self.convd5_1 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bnd5_1 = layers.BatchNormalization()\n",
    "        self.relud5_1 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd5_2 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bnd5_2 = layers.BatchNormalization()\n",
    "        self.relud5_2 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd5_3 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bnd5_3 = layers.BatchNormalization()\n",
    "        self.relud5_3 = layers.Activation('relu')\n",
    "        \n",
    "        #stage 4d\n",
    "        self.convd4_1 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bnd4_1 = layers.BatchNormalization()\n",
    "        self.relud4_1 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd4_2 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bnd4_2 = layers.BatchNormalization()\n",
    "        self.relud4_2 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd4_3 = layers.Conv2D(256,3,padding='same')\n",
    "        self.bnd4_3 = layers.BatchNormalization()\n",
    "        self.relud4_3 = layers.Activation('relu')\n",
    "        \n",
    "        #stage 3d\n",
    "        self.convd3_1 = layers.Conv2D(256,3,padding='same')\n",
    "        self.bnd3_1 = layers.BatchNormalization()\n",
    "        self.relud3_1 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd3_2 = layers.Conv2D(256,3,padding='same')\n",
    "        self.bnd3_2 = layers.BatchNormalization()\n",
    "        self.relud3_2 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd3_3 = layers.Conv2D(128,3,padding='same')\n",
    "        self.bnd3_3 = layers.BatchNormalization()\n",
    "        self.relud3_3 = layers.Activation('relu')\n",
    "        \n",
    "        #stage 2d\n",
    "        self.convd2_1 = layers.Conv2D(128,3,padding='same')\n",
    "        self.bnd2_1 = layers.BatchNormalization()\n",
    "        self.relud2_1 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd2_2 = layers.Conv2D(128,3,padding='same')\n",
    "        self.bnd2_2 = layers.BatchNormalization()\n",
    "        self.relud2_2 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd2_3 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd2_3 = layers.BatchNormalization()\n",
    "        self.relud2_3 = layers.Activation('relu')\n",
    "        \n",
    "        #stage 1d\n",
    "        self.convd1_1 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd1_1 = layers.BatchNormalization()\n",
    "        self.relud1_1 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd1_2 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd1_2 = layers.BatchNormalization()\n",
    "        self.relud1_2 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd1_3 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd1_3 = layers.BatchNormalization()\n",
    "        self.relud1_3 = layers.Activation('relu')\n",
    "        \n",
    "        #----------------------Bilinear upsampling-----------------\n",
    "        self.upscore6 = layers.UpSampling2D(32,interpolation='bilinear')###\n",
    "        self.upscore5 = layers.UpSampling2D(16,interpolation='bilinear')\n",
    "        self.upscore4 = layers.UpSampling2D(8,interpolation='bilinear')\n",
    "        self.upscore3 = layers.UpSampling2D(4,interpolation='bilinear')\n",
    "        self.upscore2 = layers.UpSampling2D(2, interpolation='bilinear')\n",
    "        \n",
    "         ## -------------Side Output--------------\n",
    "        self.outconvb = layers.Conv2D(1,3,padding=1)\n",
    "        self.outconv6 = layers.Conv2D(1,3,padding=1)\n",
    "        self.outconv5 = layers.Conv2D(1,3,padding=1)\n",
    "        self.outconv4 = layers.Conv2D(1,3,padding=1)\n",
    "        self.outconv3 = layers.Conv2D(1,3,padding=1)\n",
    "        self.outconv2 = layers.Conv2D(,3,padding=1)\n",
    "        self.outconv1 = layers.Conv2D(,3,padding=1)\n",
    "        \n",
    "        ## -------------Refine Module-------------\n",
    "        self.refunet = RefUnet(64)\n",
    "    \n",
    "    def call(self,x):\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10(tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
