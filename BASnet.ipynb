{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1db647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af382105",
   "metadata": {},
   "source": [
    "# BASNET ATTEMPT 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079857d7",
   "metadata": {},
   "source": [
    "**Basic Architecture of BASNet consist of two Module, Prediction Module and Refined Module**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f03033d",
   "metadata": {},
   "source": [
    "- lets start with prediction Module\n",
    "- Construct helper function \n",
    "- The Prediction module is U-Net like structure (encoder-decoder)\n",
    "- For Encoder we are going to use residual blocks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab448e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class basicBlock(tf.keras.Model):\n",
    "    def __init__(self,filters,stride=1):\n",
    "        super(basicBlock,self).__init__()\n",
    "        self.conv1 = layers.Conv2D(filters,3,strides = stride,padding='same')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu1 = layers.Activation('relu')\n",
    "        self.conv2 = layers.Conv2D(filters,3,strides=1,padding='same')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.relu2 = layers.Activation('relu')\n",
    "        \n",
    "    def call(self,x_in):\n",
    "        res = x_in\n",
    "        x = self.conv1(res)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = layers.add([x,res])\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "779c772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class reslayer1(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(reslayer1,self).__init__()\n",
    "        self.convblock1 = basicBlock(64)\n",
    "        self.convblock2 = basicBlock(64)\n",
    "        self.convblock3 = basicBlock(64)\n",
    "        \n",
    "    def call(self,x_in):\n",
    "        x = self.convblock1(x_in)\n",
    "        x =  slef.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f104d1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class reslayer2(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(reslayer2,self).__init__()\n",
    "        self.convblock1 = basicBlock(128,2)\n",
    "        self.convblock2 = basicBlock(128)\n",
    "        self.convblock3 = basicBlock(128)\n",
    "        self.convblock4 = basicBlock(128)\n",
    "        \n",
    "    def call(self,x_in):\n",
    "        x = self.convblock1(x_in)\n",
    "        x =  slef.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        x = self.convblock4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbe06951",
   "metadata": {},
   "outputs": [],
   "source": [
    "class reslayer3(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(reslayer3,self).__init__()\n",
    "        self.convblock1 = basicBlock(256,2)\n",
    "        self.convblock2 = basicBlock(256)\n",
    "        self.convblock3 = basicBlock(256)\n",
    "        self.convblock4 = basicBlock(256)\n",
    "        self.convblock5 = basicBlock(256)\n",
    "        self.convblock6 = basicBlock(256)\n",
    "        \n",
    "    def call(self,x_in):\n",
    "        x = self.convblock1(x_in)\n",
    "        x =  slef.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        x = self.convblock4(x)\n",
    "        x = self.convblock5(x)\n",
    "        x = self.convblock6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5f26eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class reslayer4(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(reslayer4,self).__init__()\n",
    "        self.convblock1 = basicBlock(512,2)\n",
    "        self.convblock2 = basicBlock(512)\n",
    "        self.convblock3 = basicBlock(512)\n",
    "        \n",
    "    def call(self,x_in):\n",
    "        x = self.convblock1(x_in)\n",
    "        x =  slef.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b153ddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefUnet(tf.keras.Model):\n",
    "    def __init__(self,filters):\n",
    "        super(RefUnet,self).__init__()\n",
    "        self.conv0 = layers.Conv2D(filters,3,padding='same')\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu1 = layers.Activation('relu')\n",
    "        \n",
    "        self.pool1=layers.MaxPool2D()\n",
    "        \n",
    "        self.conv2 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.relu2 = layers.Activation('relu')\n",
    "        \n",
    "        self.pool2=layers.MaxPool2D()\n",
    "        \n",
    "        self.conv3 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        self.relu3 = layers.Activation('relu')\n",
    "        \n",
    "        self.pool3=layers.MaxPool2D()\n",
    "        \n",
    "        self.conv4 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        self.relu4 = layers.Activation('relu')\n",
    "        \n",
    "        self.pool4=layers.MaxPool2D()\n",
    "        ######\n",
    "        self.conv5 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn5 = layers.BatchNormalization()\n",
    "        self.relu5 = layers.Activation('relu')\n",
    "        \n",
    "        ####\n",
    "        \n",
    "        self.convd_4 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd_4 = layers.BatchNormalization()\n",
    "        self.relud_4 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd_3 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd_3 = layers.BatchNormalization()\n",
    "        self.relud_3 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd_2 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd_2 = layers.BatchNormalization()\n",
    "        self.relud_2 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd_1 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd_1 = layers.BatchNormalization()\n",
    "        self.relud_1  = layers.Activation('relu')\n",
    "        \n",
    "        self.convd_0 = layers.Conv2D(1,3,padding='same')\n",
    "        self.upscore2 = layers.UpSampling2D(2,interpolation='bilinear')\n",
    "        \n",
    "    def call(self,x):\n",
    "        hx = x\n",
    "        hx = self.conv0(hx)\n",
    "        \n",
    "        hx1 = self.relu1(self.bn1(self.conv1(hx)))\n",
    "        hx = self.pool1(hx1)\n",
    "        \n",
    "        hx2 = self.relu2(self.bn2(self.conv2(hx)))\n",
    "        hx = self.pool2(hx2)\n",
    "        \n",
    "        hx3 = self.relu3(self.bn3(self.conv3(hx)))\n",
    "        hx = self.pool3(hx3)\n",
    "        \n",
    "        hx4 = self.relu4(self.bn4(self.conv4(hx)))\n",
    "        hx = self.pool4(hx4)\n",
    "        \n",
    "        hx5 = self.relu5(self.bn5(self.conv5(hx)))\n",
    "        \n",
    "        \n",
    "        hx = self.upscore2(hx5)\n",
    "        \n",
    "        d4 = self.relud_4(self.bnd_4(self.convd_4(layers.Concatenate(1)([hx,hx4]))))\n",
    "        hx = self.upscore2(d4)\n",
    "        \n",
    "        d3 = self.relud_3(self.bnd_3(self.convd_3(layers.Concatenate(1)([hx,hx3]))))\n",
    "        hx = self.upscore2(d3)\n",
    "        \n",
    "        d2 = self.relud_2(self.bnd_2(self.convd_2(layers.Concatenate(1)([hx,hx2]))))\n",
    "        hx = self.upscore2(d2)\n",
    "        \n",
    "        d1 = self.relud_1(self.bnd_1(self.convd_1(layers.Concatenate(1)([hx,hx1]))))\n",
    "        \n",
    "        residual = self.convd_0(d1)\n",
    "        \n",
    "        return x + residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "320021b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(BasNet,self).__init__()\n",
    "        #------------Encoeder------------------\n",
    "        \n",
    "        self.inconv = layers.Conv2D(64,3,strides = 1,padding='same')\n",
    "        self.inbn = layers.BatchNormalization()\n",
    "        self.inrelu = layers.Activation('relu')\n",
    "        \n",
    "        #stage 1 \n",
    "        self.encoder1 = reslayer1()#64\n",
    "        #stage 2 \n",
    "        self.encoder2 = reslayer2()#128\n",
    "        #stage 3\n",
    "        self.encoder3 = reslayer3()#256\n",
    "        #stage 4\n",
    "        self.encoder4 = reslayer4()#512\n",
    "        \n",
    "        self.pool4 = layers.MaxPool2D()\n",
    "        \n",
    "        #stage 5\n",
    "        self.resb5_1 = basicBlock(512)\n",
    "        self.resb5_2 = basicBlock(512)\n",
    "        self.resb5_3 = basicBlock(512)\n",
    "        \n",
    "        self.pool5 = layers.MaxPool2D()\n",
    "        \n",
    "        #stage 6\n",
    "        self.resb6_1 = basicBlock(512)\n",
    "        self.resb6_2 = basicBlock(512)\n",
    "        self.resb6_3 = basicBlock(512)\n",
    "        \n",
    "        \n",
    "        #----------------Bridge------------------------\n",
    "        #stage bridge\n",
    "        self.convbg_1 = layers.Conv2D(512,3,dilation_rate=2)\n",
    "        self.bnbg_1 = layers.BatchNormalization()\n",
    "        self.relubg_1 = layers.Activation('relu')\n",
    "        self.convbg_2 = layers.Conv2D(512,3,dilation_rate=2)\n",
    "        self.bnbg_2 = layers.BatchNormalization()\n",
    "        self.relubg_2 = layers.Activation('relu')\n",
    "        self.convbg_3 = layers.Conv2D(512,3,dilation_rate=2)\n",
    "        self.bnbg_3 = layers.BatchNormalization()\n",
    "        self.relubg_3 = layers.Activation('relu')\n",
    "        \n",
    "        #-------------------Decoder----------------------\n",
    "        \n",
    "        #stage 6d\n",
    "        self.convd6_1 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bnd6_1 = layers.BatchNormalization()\n",
    "        self.relud6_1 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd6_2 = layers.Conv2D(512,3,dilation_rate=2,padding='same')\n",
    "        self.bnd6_2 = layers.BatchNormalization()\n",
    "        self.relud6_2 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd6_3 = layers.Conv2D(512,3,dilation_rate=2,padding='same')\n",
    "        self.bnd6_3 = layers.BatchNormalization()\n",
    "        self.relud6_3 = layers.Activation('relu')\n",
    "        \n",
    "        #stage 5d\n",
    "        self.convd5_1 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bnd5_1 = layers.BatchNormalization()\n",
    "        self.relud5_1 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd5_2 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bnd5_2 = layers.BatchNormalization()\n",
    "        self.relud5_2 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd5_3 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bnd5_3 = layers.BatchNormalization()\n",
    "        self.relud5_3 = layers.Activation('relu')\n",
    "        \n",
    "        #stage 4d\n",
    "        self.convd4_1 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bnd4_1 = layers.BatchNormalization()\n",
    "        self.relud4_1 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd4_2 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bnd4_2 = layers.BatchNormalization()\n",
    "        self.relud4_2 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd4_3 = layers.Conv2D(256,3,padding='same')\n",
    "        self.bnd4_3 = layers.BatchNormalization()\n",
    "        self.relud4_3 = layers.Activation('relu')\n",
    "        \n",
    "        #stage 3d\n",
    "        self.convd3_1 = layers.Conv2D(256,3,padding='same')\n",
    "        self.bnd3_1 = layers.BatchNormalization()\n",
    "        self.relud3_1 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd3_2 = layers.Conv2D(256,3,padding='same')\n",
    "        self.bnd3_2 = layers.BatchNormalization()\n",
    "        self.relud3_2 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd3_3 = layers.Conv2D(128,3,padding='same')\n",
    "        self.bnd3_3 = layers.BatchNormalization()\n",
    "        self.relud3_3 = layers.Activation('relu')\n",
    "        \n",
    "        #stage 2d\n",
    "        self.convd2_1 = layers.Conv2D(128,3,padding='same')\n",
    "        self.bnd2_1 = layers.BatchNormalization()\n",
    "        self.relud2_1 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd2_2 = layers.Conv2D(128,3,padding='same')\n",
    "        self.bnd2_2 = layers.BatchNormalization()\n",
    "        self.relud2_2 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd2_3 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd2_3 = layers.BatchNormalization()\n",
    "        self.relud2_3 = layers.Activation('relu')\n",
    "        \n",
    "        #stage 1d\n",
    "        self.convd1_1 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd1_1 = layers.BatchNormalization()\n",
    "        self.relud1_1 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd1_2 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd1_2 = layers.BatchNormalization()\n",
    "        self.relud1_2 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd1_3 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd1_3 = layers.BatchNormalization()\n",
    "        self.relud1_3 = layers.Activation('relu')\n",
    "        \n",
    "        #----------------------Bilinear upsampling-----------------\n",
    "        self.upscore6 = layers.UpSampling2D(32,interpolation='bilinear')###\n",
    "        self.upscore5 = layers.UpSampling2D(16,interpolation='bilinear')\n",
    "        self.upscore4 = layers.UpSampling2D(8,interpolation='bilinear')\n",
    "        self.upscore3 = layers.UpSampling2D(4,interpolation='bilinear')\n",
    "        self.upscore2 = layers.UpSampling2D(2, interpolation='bilinear')\n",
    "        \n",
    "         ## -------------Side Output--------------\n",
    "        self.outconvb = layers.Conv2D(1,3,padding=1)\n",
    "        self.outconv6 = layers.Conv2D(1,3,padding=1)\n",
    "        self.outconv5 = layers.Conv2D(1,3,padding=1)\n",
    "        self.outconv4 = layers.Conv2D(1,3,padding=1)\n",
    "        self.outconv3 = layers.Conv2D(1,3,padding=1)\n",
    "        self.outconv2 = layers.Conv2D(1,3,padding=1)\n",
    "        self.outconv1 = layers.Conv2D(1,3,padding=1)\n",
    "        \n",
    "        ## -------------Refine Module-------------\n",
    "        self.refunet = RefUnet(64)\n",
    "    \n",
    "    def call(self,x):\n",
    "        hx = x \n",
    "        #-----------------Encoder------------------\n",
    "        hx = self.inconv(hx)\n",
    "        hx = self.inbn(hx)\n",
    "        hx = self.inrelu(hx)\n",
    "        \n",
    "        h1 = self.encoder1(hx)\n",
    "        h2 = self.encoder2(h1)\n",
    "        h3 = self.encoder3(h2)\n",
    "        h4 = self.encoder4(h3)\n",
    "        \n",
    "        hx = self.pool4(h4)\n",
    "        \n",
    "        hx = self.resb5_1(hx)\n",
    "        hx = self.resb5_2(hx)\n",
    "        h5 = self.resb5_3(hx)\n",
    "        \n",
    "        hx = self.pool5(h5)\n",
    "        \n",
    "        hx = self.resb6_1(hx)\n",
    "        hx = self.resb6_2(hx)\n",
    "        h6 = self.resb6_3(hx)\n",
    "        \n",
    "        #-----------------------Bridge-------------------\n",
    "        \n",
    "        hx = self.relubg_1(self.bnbg_1(self.convbg_1(h6)))\n",
    "        hx = self.relubg_2(self.bnbg_2(self.convbg_2(hx)))\n",
    "        hbg = self.relubg_3(self.bnbg_3(self.convbg_3(hx)))\n",
    "        \n",
    "        #-----------------------Decoder--------------------\n",
    "        \n",
    "        hx = self.relud6_1(self.bnd6_1(self.convd6_1(layers.concatenate(1)([hbg,h6]))))\n",
    "        hx = self.relud6_2(self.bnd6_2(self.convd6_2(hx)))\n",
    "        hd6 = self.relud6_3(self.bnd6_3(self.convd6_3(hx)))\n",
    "        \n",
    "        hx = self.upscore2(hd6)\n",
    "        \n",
    "        hx = self.relud5_1(self.bnd5_1(self.convd5_1(layers.concatenate(1)([hbg,h5]))))\n",
    "        hx = self.relud5_2(self.bnd5_2(self.convd5_2(hx)))\n",
    "        hd5 = self.relud5_3(self.bnd5_3(self.convd5_3(hx)))\n",
    "        \n",
    "        hx = self.upscore2(hd5)\n",
    "        \n",
    "        hx = self.relud4_1(self.bnd4_1(self.convd4_1(layers.concatenate(1)([hbg,h4]))))\n",
    "        hx = self.relud4_2(self.bnd4_2(self.convd4_2(hx)))\n",
    "        hd4 = self.relud4_3(self.bnd4_3(self.convd4_3(hx)))\n",
    "        \n",
    "        hx = self.upscore2(hd4)\n",
    "        \n",
    "        hx = self.relud3_1(self.bnd3_1(self.convd3_1(layers.concatenate(1)([hbg,h3]))))\n",
    "        hx = self.relud3_2(self.bnd3_2(self.convd3_2(hx)))\n",
    "        hd3 = self.relud3_3(self.bnd3_3(self.convd3_3(hx)))\n",
    "        \n",
    "        hx = self.upscore2(hd3)\n",
    "        \n",
    "        hx = self.relud2_1(self.bnd2_1(self.convd2_1(layers.concatenate(1)([hbg,h2]))))\n",
    "        hx = self.relud2_2(self.bnd2_2(self.convd2_2(hx)))\n",
    "        hd2 = self.relud2_3(self.bnd2_3(self.convd2_3(hx)))\n",
    "        \n",
    "        hx = self.upscore2(hd2)\n",
    "        \n",
    "        hx = self.relud1_1(self.bnd1_1(self.convd1_1(layers.concatenate(1)([hbg,h1]))))\n",
    "        hx = self.relud1_2(self.bnd1_2(self.convd1_2(hx)))\n",
    "        hd1 = self.relud1_3(self.bnd1_3(self.convd1_3(hx)))\n",
    "        \n",
    "        #------------------------------side output------------------------\n",
    "        \n",
    "        db = self.outconvb(hbg)\n",
    "        db = self.upscore6(db)\n",
    "        \n",
    "        d6 = self.outconv6(hd6)\n",
    "        d6 = self.upscore6(d6)\n",
    "        \n",
    "        d5 = self.outconv5(hd5)\n",
    "        d5 = self.upscore5(d5)\n",
    "        \n",
    "        d4 = self.outconv4(hd4)\n",
    "        d4 = self.upscore4(d4)\n",
    "        \n",
    "        d3 = self.outconv3(hd3)\n",
    "        d3 = self.upscore3(d3)\n",
    "        \n",
    "        d2 = self.outconv6(hd2)\n",
    "        d2 = self.upscore6(d2)\n",
    "        \n",
    "        d1 = self.outconv1(hd1)\n",
    "        \n",
    "        #-----------------------------Refine Module--------------\n",
    "        dout = self.refunet(hd1)\n",
    "        \n",
    "        return tf.sigmoid(dout), tf.sigmoid(d1), tf.sigmoid(d2), tf.sigmoid(d3), tf.sigmoid(d4), tf.sigmoid(d5), tf.sigmoid(d6), tf.sigmoid(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43c1ffe3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBasNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36mBasNet.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupscore2 \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mUpSampling2D(\u001b[38;5;241m2\u001b[39m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    133\u001b[0m  \u001b[38;5;66;03m## -------------Side Output--------------\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutconvb \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutconv6 \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutconv5 \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mE:\\MACHINELEARNING\\TENSORFLOW_P\\tensorflow\\lib\\site-packages\\keras\\dtensor\\utils.py:95\u001b[0m, in \u001b[0;36mallow_initializer_layout.<locals>._wrap_function\u001b[1;34m(layer_instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layout:\n\u001b[0;32m     93\u001b[0m       layout_args[variable_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_layout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m layout\n\u001b[1;32m---> 95\u001b[0m init_method(layer_instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Inject the layout parameter after the invocation of __init__()\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layout_param_name, layout \u001b[38;5;129;01min\u001b[39;00m layout_args\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mE:\\MACHINELEARNING\\TENSORFLOW_P\\tensorflow\\lib\\site-packages\\keras\\layers\\convolutional\\conv2d.py:170\u001b[0m, in \u001b[0;36mConv2D.__init__\u001b[1;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;129m@utils\u001b[39m\u001b[38;5;241m.\u001b[39mallow_initializer_layout\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    153\u001b[0m              filters,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    168\u001b[0m              bias_constraint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    169\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 170\u001b[0m   \u001b[38;5;28msuper\u001b[39m(Conv2D, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    171\u001b[0m       rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    172\u001b[0m       filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[0;32m    173\u001b[0m       kernel_size\u001b[38;5;241m=\u001b[39mkernel_size,\n\u001b[0;32m    174\u001b[0m       strides\u001b[38;5;241m=\u001b[39mstrides,\n\u001b[0;32m    175\u001b[0m       padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m    176\u001b[0m       data_format\u001b[38;5;241m=\u001b[39mdata_format,\n\u001b[0;32m    177\u001b[0m       dilation_rate\u001b[38;5;241m=\u001b[39mdilation_rate,\n\u001b[0;32m    178\u001b[0m       groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m    179\u001b[0m       activation\u001b[38;5;241m=\u001b[39mactivations\u001b[38;5;241m.\u001b[39mget(activation),\n\u001b[0;32m    180\u001b[0m       use_bias\u001b[38;5;241m=\u001b[39muse_bias,\n\u001b[0;32m    181\u001b[0m       kernel_initializer\u001b[38;5;241m=\u001b[39minitializers\u001b[38;5;241m.\u001b[39mget(kernel_initializer),\n\u001b[0;32m    182\u001b[0m       bias_initializer\u001b[38;5;241m=\u001b[39minitializers\u001b[38;5;241m.\u001b[39mget(bias_initializer),\n\u001b[0;32m    183\u001b[0m       kernel_regularizer\u001b[38;5;241m=\u001b[39mregularizers\u001b[38;5;241m.\u001b[39mget(kernel_regularizer),\n\u001b[0;32m    184\u001b[0m       bias_regularizer\u001b[38;5;241m=\u001b[39mregularizers\u001b[38;5;241m.\u001b[39mget(bias_regularizer),\n\u001b[0;32m    185\u001b[0m       activity_regularizer\u001b[38;5;241m=\u001b[39mregularizers\u001b[38;5;241m.\u001b[39mget(activity_regularizer),\n\u001b[0;32m    186\u001b[0m       kernel_constraint\u001b[38;5;241m=\u001b[39mconstraints\u001b[38;5;241m.\u001b[39mget(kernel_constraint),\n\u001b[0;32m    187\u001b[0m       bias_constraint\u001b[38;5;241m=\u001b[39mconstraints\u001b[38;5;241m.\u001b[39mget(bias_constraint),\n\u001b[0;32m    188\u001b[0m       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\MACHINELEARNING\\TENSORFLOW_P\\tensorflow\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py:131\u001b[0m, in \u001b[0;36mConv.__init__\u001b[1;34m(self, rank, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, conv_op, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size \u001b[38;5;241m=\u001b[39m conv_utils\u001b[38;5;241m.\u001b[39mnormalize_tuple(\n\u001b[0;32m    128\u001b[0m     kernel_size, rank, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel_size\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrides \u001b[38;5;241m=\u001b[39m conv_utils\u001b[38;5;241m.\u001b[39mnormalize_tuple(\n\u001b[0;32m    130\u001b[0m     strides, rank, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrides\u001b[39m\u001b[38;5;124m'\u001b[39m, allow_zero\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding \u001b[38;5;241m=\u001b[39m \u001b[43mconv_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_padding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_format \u001b[38;5;241m=\u001b[39m conv_utils\u001b[38;5;241m.\u001b[39mnormalize_data_format(data_format)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation_rate \u001b[38;5;241m=\u001b[39m conv_utils\u001b[38;5;241m.\u001b[39mnormalize_tuple(\n\u001b[0;32m    134\u001b[0m     dilation_rate, rank, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdilation_rate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mE:\\MACHINELEARNING\\TENSORFLOW_P\\tensorflow\\lib\\site-packages\\keras\\utils\\conv_utils.py:219\u001b[0m, in \u001b[0;36mnormalize_padding\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m--> 219\u001b[0m padding \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padding \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcausal\u001b[39m\u001b[38;5;124m'\u001b[39m}:\n\u001b[0;32m    221\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe `padding` argument must be a list/tuple or one of \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    222\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (or \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcausal\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, only for `Conv1D). \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    223\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpadding\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "model = BasNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b4076",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build([None,224,224,3])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9c43b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10(tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
