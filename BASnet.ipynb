{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1db647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af382105",
   "metadata": {},
   "source": [
    "# BASNET ATTEMPT 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079857d7",
   "metadata": {},
   "source": [
    "**Basic Architecture of BASNet consist of two Module, Prediction Module and Refined Module**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f03033d",
   "metadata": {},
   "source": [
    "- lets start with prediction Module\n",
    "- Construct helper function \n",
    "- The Prediction module is U-Net like structure (encoder-decoder)\n",
    "- For Encoder we are going to use residual blocks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9694eb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class downsample(tf.keras.Model):\n",
    "    def __init__(self,filters,stride=1):\n",
    "        super(downsample,self).__init__()\n",
    "        self.conv = layers.Conv2D(filters,1,strides=stride,padding='same',use_bias=False)\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.relu = layers.Activation('relu')\n",
    "        \n",
    "    def call(self,x):\n",
    "        res = x \n",
    "        x = self.conv(res)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab448e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class basicBlock(tf.keras.Model):\n",
    "    def __init__(self,filters,stride=1,downsamples=False):\n",
    "        super(basicBlock,self).__init__()\n",
    "        self.conv1 = layers.Conv2D(filters,3,strides = stride,padding='same')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu1 = layers.Activation('relu')\n",
    "        self.conv2 = layers.Conv2D(filters,3,strides=1,padding='same')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.relu2 = layers.Activation('relu')\n",
    "        self.downsamples = downsamples\n",
    "        if self.downsamples:\n",
    "            self.dsmp = downsample(filters,stride)\n",
    "        \n",
    "    def call(self,x_in):\n",
    "        res = x_in\n",
    "        x = self.conv1(res)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.downsamples:\n",
    "            res = self.dsmp(res)\n",
    "        x = layers.Add()([x,res])\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "779c772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class reslayer1(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(reslayer1,self).__init__()\n",
    "        self.convblock1 = basicBlock(64)\n",
    "        self.convblock2 = basicBlock(64)\n",
    "        self.convblock3 = basicBlock(64)\n",
    "        \n",
    "    def call(self,x_in):\n",
    "        x = self.convblock1(x_in)\n",
    "        x =  self.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f104d1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class reslayer2(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(reslayer2,self).__init__()\n",
    "        self.convblock1 = basicBlock(128,2,downsamples=True)\n",
    "        self.convblock2 = basicBlock(128)\n",
    "        self.convblock3 = basicBlock(128)\n",
    "        self.convblock4 = basicBlock(128)\n",
    "        \n",
    "    def call(self,x_in):\n",
    "        x = self.convblock1(x_in)\n",
    "        x =  self.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        x = self.convblock4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbe06951",
   "metadata": {},
   "outputs": [],
   "source": [
    "class reslayer3(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(reslayer3,self).__init__()\n",
    "        self.convblock1 = basicBlock(256,2,downsamples=True)\n",
    "        self.convblock2 = basicBlock(256)\n",
    "        self.convblock3 = basicBlock(256)\n",
    "        self.convblock4 = basicBlock(256)\n",
    "        self.convblock5 = basicBlock(256)\n",
    "        self.convblock6 = basicBlock(256)\n",
    "        \n",
    "    def call(self,x_in):\n",
    "        x = self.convblock1(x_in)\n",
    "        x =  self.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        x = self.convblock4(x)\n",
    "        x = self.convblock5(x)\n",
    "        x = self.convblock6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5f26eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class reslayer4(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(reslayer4,self).__init__()\n",
    "        self.convblock1 = basicBlock(512,2,downsamples=True)\n",
    "        self.convblock2 = basicBlock(512)\n",
    "        self.convblock3 = basicBlock(512)\n",
    "        \n",
    "    def call(self,x_in):\n",
    "        x = self.convblock1(x_in)\n",
    "        x =  self.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b153ddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefUnet(tf.keras.Model):\n",
    "    def __init__(self,filters):\n",
    "        super(RefUnet,self).__init__()\n",
    "        self.conv0 = layers.Conv2D(filters,3,padding='same')\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu1 = layers.Activation('relu')\n",
    "        \n",
    "        self.pool1=layers.MaxPool2D()\n",
    "        \n",
    "        self.conv2 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.relu2 = layers.Activation('relu')\n",
    "        \n",
    "        self.pool2=layers.MaxPool2D()\n",
    "        \n",
    "        self.conv3 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        self.relu3 = layers.Activation('relu')\n",
    "        \n",
    "        self.pool3=layers.MaxPool2D()\n",
    "        \n",
    "        self.conv4 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        self.relu4 = layers.Activation('relu')\n",
    "        \n",
    "        self.pool4=layers.MaxPool2D()\n",
    "        ######\n",
    "        self.conv5 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bn5 = layers.BatchNormalization()\n",
    "        self.relu5 = layers.Activation('relu')\n",
    "        \n",
    "        ####\n",
    "        \n",
    "        self.convd_4 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd_4 = layers.BatchNormalization()\n",
    "        self.relud_4 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd_3 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd_3 = layers.BatchNormalization()\n",
    "        self.relud_3 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd_2 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd_2 = layers.BatchNormalization()\n",
    "        self.relud_2 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd_1 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd_1 = layers.BatchNormalization()\n",
    "        self.relud_1  = layers.Activation('relu')\n",
    "        \n",
    "        self.convd_0 = layers.Conv2D(1,3,padding='same')\n",
    "        self.upscore2 = layers.UpSampling2D(2,interpolation='bilinear')\n",
    "        \n",
    "    def call(self,x):\n",
    "        hx = x\n",
    "        hx = self.conv0(hx)\n",
    "        \n",
    "        hx1 = self.relu1(self.bn1(self.conv1(hx)))\n",
    "        hx = self.pool1(hx1)\n",
    "        \n",
    "        hx2 = self.relu2(self.bn2(self.conv2(hx)))\n",
    "        hx = self.pool2(hx2)\n",
    "        \n",
    "        hx3 = self.relu3(self.bn3(self.conv3(hx)))\n",
    "        hx = self.pool3(hx3)\n",
    "        \n",
    "        hx4 = self.relu4(self.bn4(self.conv4(hx)))\n",
    "        hx = self.pool4(hx4)\n",
    "        \n",
    "        hx5 = self.relu5(self.bn5(self.conv5(hx)))\n",
    "        \n",
    "        \n",
    "        hx = self.upscore2(hx5)\n",
    "        \n",
    "        d4 = self.relud_4(self.bnd_4(self.convd_4(layers.Concatenate(1)([hx,hx4]))))\n",
    "        hx = self.upscore2(d4)\n",
    "        \n",
    "        d3 = self.relud_3(self.bnd_3(self.convd_3(layers.Concatenate(1)([hx,hx3]))))\n",
    "        hx = self.upscore2(d3)\n",
    "        \n",
    "        d2 = self.relud_2(self.bnd_2(self.convd_2(layers.Concatenate(1)([hx,hx2]))))\n",
    "        hx = self.upscore2(d2)\n",
    "        \n",
    "        d1 = self.relud_1(self.bnd_1(self.convd_1(layers.Concatenate(1)([hx,hx1]))))\n",
    "        \n",
    "        residual = self.convd_0(d1)\n",
    "        \n",
    "        return x + residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "320021b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(BasNet,self).__init__()\n",
    "        #------------Encoeder------------------\n",
    "        \n",
    "        self.inconv = layers.Conv2D(64,3,strides = 1,padding='same')\n",
    "        self.inbn = layers.BatchNormalization()\n",
    "        self.inrelu = layers.Activation('relu')\n",
    "        \n",
    "        #stage 1 \n",
    "        self.encoder1 = reslayer1()#64\n",
    "        #stage 2 \n",
    "        self.encoder2 = reslayer2()#128\n",
    "        #stage 3\n",
    "        self.encoder3 = reslayer3()#256\n",
    "        #stage 4\n",
    "        self.encoder4 = reslayer4()#512\n",
    "        \n",
    "        \n",
    "        \n",
    "        #stage 5\n",
    "        self.pool4 = layers.MaxPool2D(strides=(2,2))\n",
    "        self.resb5_1 = basicBlock(512,downsamples=True)\n",
    "        self.resb5_2 = basicBlock(512)\n",
    "        self.resb5_3 = basicBlock(512)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #stage 6\n",
    "        self.pool5 = layers.MaxPool2D(strides=(2,2))\n",
    "        self.resb6_1 = basicBlock(512)\n",
    "        self.resb6_2 = basicBlock(512)\n",
    "        self.resb6_3 = basicBlock(512)\n",
    "        \n",
    "        \n",
    "        #----------------Bridge------------------------\n",
    "        #stage bridge\n",
    "        self.convbg_1 = layers.Conv2D(512,3,dilation_rate=2,padding='same')\n",
    "        self.bnbg_1 = layers.BatchNormalization()\n",
    "        self.relubg_1 = layers.Activation('relu')\n",
    "        self.convbg_2 = layers.Conv2D(512,3,dilation_rate=2,padding='same')\n",
    "        self.bnbg_2 = layers.BatchNormalization()\n",
    "        self.relubg_2 = layers.Activation('relu')\n",
    "        self.convbg_3 = layers.Conv2D(512,3,dilation_rate=2,padding='same')\n",
    "        self.bnbg_3 = layers.BatchNormalization()\n",
    "        self.relubg_3 = layers.Activation('relu')\n",
    "        \n",
    "        #-------------------Decoder----------------------\n",
    "        \n",
    "        #stage 6d\n",
    "        self.convd6_1 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bnd6_1 = layers.BatchNormalization()\n",
    "        self.relud6_1 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd6_2 = layers.Conv2D(512,3,dilation_rate=2,padding='same')\n",
    "        self.bnd6_2 = layers.BatchNormalization()\n",
    "        self.relud6_2 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd6_3 = layers.Conv2D(512,3,dilation_rate=2,padding='same')\n",
    "        self.bnd6_3 = layers.BatchNormalization()\n",
    "        self.relud6_3 = layers.Activation('relu')\n",
    "        \n",
    "        #stage 5d\n",
    "        self.convd5_1 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bnd5_1 = layers.BatchNormalization()\n",
    "        self.relud5_1 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd5_2 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bnd5_2 = layers.BatchNormalization()\n",
    "        self.relud5_2 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd5_3 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bnd5_3 = layers.BatchNormalization()\n",
    "        self.relud5_3 = layers.Activation('relu')\n",
    "        \n",
    "        #stage 4d\n",
    "        self.convd4_1 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bnd4_1 = layers.BatchNormalization()\n",
    "        self.relud4_1 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd4_2 = layers.Conv2D(512,3,padding='same')\n",
    "        self.bnd4_2 = layers.BatchNormalization()\n",
    "        self.relud4_2 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd4_3 = layers.Conv2D(256,3,padding='same')\n",
    "        self.bnd4_3 = layers.BatchNormalization()\n",
    "        self.relud4_3 = layers.Activation('relu')\n",
    "        \n",
    "        #stage 3d\n",
    "        self.convd3_1 = layers.Conv2D(256,3,padding='same')\n",
    "        self.bnd3_1 = layers.BatchNormalization()\n",
    "        self.relud3_1 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd3_2 = layers.Conv2D(256,3,padding='same')\n",
    "        self.bnd3_2 = layers.BatchNormalization()\n",
    "        self.relud3_2 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd3_3 = layers.Conv2D(128,3,padding='same')\n",
    "        self.bnd3_3 = layers.BatchNormalization()\n",
    "        self.relud3_3 = layers.Activation('relu')\n",
    "        \n",
    "        #stage 2d\n",
    "        self.convd2_1 = layers.Conv2D(128,3,padding='same')\n",
    "        self.bnd2_1 = layers.BatchNormalization()\n",
    "        self.relud2_1 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd2_2 = layers.Conv2D(128,3,padding='same')\n",
    "        self.bnd2_2 = layers.BatchNormalization()\n",
    "        self.relud2_2 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd2_3 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd2_3 = layers.BatchNormalization()\n",
    "        self.relud2_3 = layers.Activation('relu')\n",
    "        \n",
    "        #stage 1d\n",
    "        self.convd1_1 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd1_1 = layers.BatchNormalization()\n",
    "        self.relud1_1 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd1_2 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd1_2 = layers.BatchNormalization()\n",
    "        self.relud1_2 = layers.Activation('relu')\n",
    "        \n",
    "        self.convd1_3 = layers.Conv2D(64,3,padding='same')\n",
    "        self.bnd1_3 = layers.BatchNormalization()\n",
    "        self.relud1_3 = layers.Activation('relu')\n",
    "        \n",
    "        #----------------------Bilinear upsampling-----------------\n",
    "        self.upscore6 = layers.UpSampling2D(32,interpolation='bilinear')###\n",
    "        self.upscore5 = layers.UpSampling2D(16,interpolation='bilinear')\n",
    "        self.upscore4 = layers.UpSampling2D(8,interpolation='bilinear')\n",
    "        self.upscore3 = layers.UpSampling2D(4,interpolation='bilinear')\n",
    "        self.upscore2 = layers.UpSampling2D(2, interpolation='bilinear')\n",
    "        \n",
    "         ## -------------Side Output--------------\n",
    "        self.outconvb = layers.Conv2D(1,3,padding='same')\n",
    "        self.outconv6 = layers.Conv2D(1,3,padding='same')\n",
    "        self.outconv5 = layers.Conv2D(1,3,padding='same')\n",
    "        self.outconv4 = layers.Conv2D(1,3,padding='same')\n",
    "        self.outconv3 = layers.Conv2D(1,3,padding='same')\n",
    "        self.outconv2 = layers.Conv2D(1,3,padding='same')\n",
    "        self.outconv1 = layers.Conv2D(1,3,padding='same')\n",
    "        \n",
    "        ## -------------Refine Module-------------\n",
    "        self.refunet = RefUnet(64)\n",
    "    \n",
    "    def call(self,x):\n",
    "        hx = x \n",
    "        #-----------------Encoder------------------\n",
    "        hx = self.inconv(hx)\n",
    "        hx = self.inbn(hx)\n",
    "        hx = self.inrelu(hx)\n",
    "        #----------------e1---------------\n",
    "        h1 = self.encoder1(hx)\n",
    "        #----------------e2---------------\n",
    "        h2 = self.encoder2(h1)\n",
    "        #----------------e3---------------\n",
    "        h3 = self.encoder3(h2)\n",
    "        #----------------e4---------------\n",
    "        h4 = self.encoder4(h3)\n",
    "        \n",
    "        hx = self.pool4(h4)\n",
    "        \n",
    "        \n",
    "        hx = self.resb5_1(hx)\n",
    "        hx = self.resb5_2(hx)\n",
    "        h5 = self.resb5_3(hx)\n",
    "        \n",
    "        hx = self.pool5(h5)\n",
    "        \n",
    "        hx = self.resb6_1(hx)\n",
    "        hx = self.resb6_2(hx)\n",
    "        h6 = self.resb6_3(hx)\n",
    "        \n",
    "        #-----------------------Bridge-------------------\n",
    "        \n",
    "        hx = self.relubg_1(self.bnbg_1(self.convbg_1(h6)))\n",
    "        hx = self.relubg_2(self.bnbg_2(self.convbg_2(hx)))\n",
    "        hbg = self.relubg_3(self.bnbg_3(self.convbg_3(hx)))\n",
    "        \n",
    "        #-----------------------Decoder--------------------\n",
    "        \n",
    "        hx = self.relud6_1(self.bnd6_1(self.convd6_1(layers.concatenate([hbg,h6],-1))))\n",
    "        hx = self.relud6_2(self.bnd6_2(self.convd6_2(hx)))\n",
    "        hd6 = self.relud6_3(self.bnd6_3(self.convd6_3(hx)))\n",
    "        \n",
    "        hx = self.upscore2(hd6)\n",
    "        \n",
    "        hx = self.relud5_1(self.bnd5_1(self.convd5_1(layers.concatenate([hx,h5],-1))))\n",
    "        hx = self.relud5_2(self.bnd5_2(self.convd5_2(hx)))\n",
    "        hd5 = self.relud5_3(self.bnd5_3(self.convd5_3(hx)))\n",
    "        \n",
    "        hx = self.upscore2(hd5)\n",
    "        \n",
    "        hx = self.relud4_1(self.bnd4_1(self.convd4_1(layers.concatenate([hx,h4],-1))))\n",
    "        hx = self.relud4_2(self.bnd4_2(self.convd4_2(hx)))\n",
    "        hd4 = self.relud4_3(self.bnd4_3(self.convd4_3(hx)))\n",
    "        \n",
    "        hx = self.upscore2(hd4)\n",
    "        \n",
    "        hx = self.relud3_1(self.bnd3_1(self.convd3_1(layers.concatenate([hx,h3],-1))))\n",
    "        hx = self.relud3_2(self.bnd3_2(self.convd3_2(hx)))\n",
    "        hd3 = self.relud3_3(self.bnd3_3(self.convd3_3(hx)))\n",
    "        \n",
    "        hx = self.upscore2(hd3)\n",
    "        \n",
    "        hx = self.relud2_1(self.bnd2_1(self.convd2_1(layers.concatenate([hx,h2],-1))))\n",
    "        hx = self.relud2_2(self.bnd2_2(self.convd2_2(hx)))\n",
    "        hd2 = self.relud2_3(self.bnd2_3(self.convd2_3(hx)))\n",
    "        \n",
    "        hx = self.upscore2(hd2)\n",
    "        \n",
    "        hx = self.relud1_1(self.bnd1_1(self.convd1_1(layers.concatenate([hx,h1],-1))))\n",
    "        hx = self.relud1_2(self.bnd1_2(self.convd1_2(hx)))\n",
    "        hd1 = self.relud1_3(self.bnd1_3(self.convd1_3(hx)))\n",
    "        \n",
    "        #------------------------------side output------------------------\n",
    "        \n",
    "        db = self.outconvb(hbg)\n",
    "        db = self.upscore6(db)\n",
    "        \n",
    "        d6 = self.outconv6(hd6)\n",
    "        d6 = self.upscore6(d6)\n",
    "        \n",
    "        d5 = self.outconv5(hd5)\n",
    "        d5 = self.upscore5(d5)\n",
    "        \n",
    "        d4 = self.outconv4(hd4)\n",
    "        d4 = self.upscore4(d4)\n",
    "        \n",
    "        d3 = self.outconv3(hd3)\n",
    "        d3 = self.upscore3(d3)\n",
    "        \n",
    "        d2 = self.outconv2(hd2)\n",
    "        d2 = self.upscore2(d2)\n",
    "        \n",
    "        d1 = self.outconv1(hd1)\n",
    "        \n",
    "        #-----------------------------Refine Module--------------\n",
    "        dout = self.refunet(d1)\n",
    "        \n",
    "        return tf.sigmoid(dout), tf.sigmoid(d1), tf.sigmoid(d2), tf.sigmoid(d3), tf.sigmoid(d4), tf.sigmoid(d5), tf.sigmoid(d6), tf.sigmoid(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "43c1ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f39b4076",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"ref_unet_21\" (type RefUnet).\n\nin user code:\n\n    File \"C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_6528\\3929176119.py\", line 89, in call  *\n        return x + residual\n\n    ValueError: Dimensions must be equal, but are 224 and 1120 for '{{node ref_unet_21/add}} = AddV2[T=DT_FLOAT](conv2d_1925/BiasAdd, ref_unet_21/conv2d_1936/BiasAdd)' with input shapes: [?,224,224,1], [?,1120,224,1].\n\n\nCall arguments received by layer \"ref_unet_21\" (type RefUnet):\n  • x=tf.Tensor(shape=(None, 224, 224, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [91]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[1;32mE:\\MACHINELEARNING\\TENSORFLOW_P\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:449\u001b[0m, in \u001b[0;36mModel.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    445\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    446\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou can only call `build()` on a model if its `call()` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    447\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod accepts an `inputs` argument.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 449\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mInvalidArgumentError, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    451\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou cannot build your model by calling `build` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    452\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mif your layers do not support float type inputs. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    453\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInstead, in order to instantiate and build your \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    454\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel, call your model on real tensor data (of \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    455\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe correct dtype).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThe actual error from \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    456\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`call` is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [89]\u001b[0m, in \u001b[0;36mBasNet.call\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    237\u001b[0m d1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutconv1(hd1)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m#-----------------------------Refine Module--------------\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m dout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefunet\u001b[49m\u001b[43m(\u001b[49m\u001b[43md1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39msigmoid(dout), tf\u001b[38;5;241m.\u001b[39msigmoid(d1), tf\u001b[38;5;241m.\u001b[39msigmoid(d2), tf\u001b[38;5;241m.\u001b[39msigmoid(d3), tf\u001b[38;5;241m.\u001b[39msigmoid(d4), tf\u001b[38;5;241m.\u001b[39msigmoid(d5), tf\u001b[38;5;241m.\u001b[39msigmoid(d6), tf\u001b[38;5;241m.\u001b[39msigmoid(db)\n",
      "File \u001b[1;32mE:\\MACHINELEARNING\\TENSORFLOW_P\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file8lswmil8.py:32\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(x) \u001b[38;5;241m+\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(residual)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"ref_unet_21\" (type RefUnet).\n\nin user code:\n\n    File \"C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_6528\\3929176119.py\", line 89, in call  *\n        return x + residual\n\n    ValueError: Dimensions must be equal, but are 224 and 1120 for '{{node ref_unet_21/add}} = AddV2[T=DT_FLOAT](conv2d_1925/BiasAdd, ref_unet_21/conv2d_1936/BiasAdd)' with input shapes: [?,224,224,1], [?,1120,224,1].\n\n\nCall arguments received by layer \"ref_unet_21\" (type RefUnet):\n  • x=tf.Tensor(shape=(None, 224, 224, 1), dtype=float32)"
     ]
    }
   ],
   "source": [
    "model.build([None,224,224,3])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e5f2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10(tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
